{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XGBoost CV (LB .284)",
      "provenance": [],
      "authorship_tag": "ABX9TyP9kcMyiYXkQtsvyr3nhTef"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0Eus6S155ySu"
      },
      "outputs": [],
      "source": [
        "#hyper parameter\n",
        "MAX_ROUNDS = 400\n",
        "OPTIMIZE_ROUNDS = False#stacking and ensembling\n",
        "LEARNING_RATE = 0.07\n",
        "EARLY_STOPPING_ROUNDS = 50 #epochs\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from numba import jit #in-time compiler, parallelings process\n",
        "import time \n",
        "#import gx"
      ],
      "metadata": {
        "id": "wynA6a7v50o5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jit\n",
        "def eval_gini(y_true, y_prob):\n",
        "    y_true = np.asarray(y_true)\n",
        "    y_true = y_true[np.argsort(y_prob)]\n",
        "    ntrue = 0\n",
        "    gini = 0\n",
        "    delta = 0\n",
        "    n = len(y_true)\n",
        "    for i in range(n-1, -1, -1):\n",
        "        y_i = y_true[i]\n",
        "        ntrue += y_i\n",
        "        gini += y_i * delta\n",
        "        delta += 1 - y_i\n",
        "    gini = 1 - 2 * gini / (ntrue * (n- ntrue))\n",
        "    return gini"
      ],
      "metadata": {
        "id": "_O_2v_cP6Zl-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gini_xgb(preds, dtrain):\n",
        "    labels = dtrain.get_label()\n",
        "    gini_score = -eval_gini(labels, preds)\n",
        "    return [('gini', gini_score)]\n",
        "\n",
        "\n",
        "def add_noise(series, noise_level):\n",
        "    return series * (1 + noise_level * np.random.randn(len(series)))\n",
        "\n",
        "\n",
        "def target_encode(trn_series=None,    # Revised to encode validation series\n",
        "                  val_series=None,\n",
        "                  tst_series=None,\n",
        "                  target=None,\n",
        "                  min_samples_leaf=1,\n",
        "                  smoothing=1,\n",
        "                  noise_level=0):\n",
        "\n",
        "    assert len(trn_series) == len(target)\n",
        "    assert trn_series.name == tst_series.name\n",
        "    temp = pd.concat([trn_series, target], axis=1)\n",
        "    # Compute target mean\n",
        "    averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n",
        "    # Compute smoothing\n",
        "    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n",
        "    # Apply average function to all target data\n",
        "    prior = target.mean()\n",
        "    # The bigger the count the less full_avg is taken into account\n",
        "    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
        "    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n",
        "    # Apply averages to trn and tst series\n",
        "    ft_trn_series = pd.merge(\n",
        "        trn_series.to_frame(trn_series.name),\n",
        "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
        "        on=trn_series.name,\n",
        "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
        "    # pd.merge does not keep the index so restore it\n",
        "    ft_trn_series.index = trn_series.index\n",
        "    ft_val_series = pd.merge(\n",
        "        val_series.to_frame(val_series.name),\n",
        "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
        "        on=val_series.name,\n",
        "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
        "    # pd.merge does not keep the index so restore it\n",
        "    ft_val_series.index = val_series.index\n",
        "    ft_tst_series = pd.merge(\n",
        "        tst_series.to_frame(tst_series.name),\n",
        "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
        "        on=tst_series.name,\n",
        "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
        "    # pd.merge does not keep the index so restore it\n",
        "    ft_tst_series.index = tst_series.index\n",
        "    return add_noise(ft_trn_series, noise_level), add_noise(ft_val_series, noise_level), add_noise(ft_tst_series, noise_level)"
      ],
      "metadata": {
        "id": "rzmWIKvt6ZuT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load data\n",
        "train_df = pd.read_csv('./input/train 2.csv', na_values='-1') #.iloc[0:200,:]\n",
        "test_df = pd.read_csv('./input/test 2.csv', na_values='-1')"
      ],
      "metadata": {
        "id": "9E_OEijJCCRA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#features\n",
        "train_features = [\n",
        "    \"ps_car_13\",  #            : 1571.65 / shadow  609.23\n",
        "\t\"ps_reg_03\",  #            : 1408.42 / shadow  511.15\n",
        "\t\"ps_ind_05_cat\",  #        : 1387.87 / shadow   84.72\n",
        "\t\"ps_ind_03\",  #            : 1219.47 / shadow  230.55\n",
        "\t\"ps_ind_15\",  #            :  922.18 / shadow  242.00\n",
        "\t\"ps_reg_02\",  #            :  920.65 / shadow  267.50\n",
        "\t\"ps_car_14\",  #            :  798.48 / shadow  549.58\n",
        "\t\"ps_car_12\",  #            :  731.93 / shadow  293.62\n",
        "\t\"ps_car_01_cat\",  #        :  698.07 / shadow  178.72\n",
        "\t\"ps_car_07_cat\",  #        :  694.53 / shadow   36.35\n",
        "\t\"ps_ind_17_bin\",  #        :  620.77 / shadow   23.15\n",
        "\t\"ps_car_03_cat\",  #        :  611.73 / shadow   50.67\n",
        "\t\"ps_reg_01\",  #            :  598.60 / shadow  178.57\n",
        "\t\"ps_car_15\",  #            :  593.35 / shadow  226.43\n",
        "\t\"ps_ind_01\",  #            :  547.32 / shadow  154.58\n",
        "\t\"ps_ind_16_bin\",  #        :  475.37 / shadow   34.17\n",
        "\t\"ps_ind_07_bin\",  #        :  435.28 / shadow   28.92\n",
        "\t\"ps_car_06_cat\",  #        :  398.02 / shadow  212.43\n",
        "\t\"ps_car_04_cat\",  #        :  376.87 / shadow   76.98\n",
        "\t\"ps_ind_06_bin\",  #        :  370.97 / shadow   36.13\n",
        "\t\"ps_car_09_cat\",  #        :  214.12 / shadow   81.38\n",
        "\t\"ps_car_02_cat\",  #        :  203.03 / shadow   26.67\n",
        "\t\"ps_ind_02_cat\",  #        :  189.47 / shadow   65.68\n",
        "\t\"ps_car_11\",  #            :  173.28 / shadow   76.45\n",
        "\t\"ps_car_05_cat\",  #        :  172.75 / shadow   62.92\n",
        "\t\"ps_calc_09\",  #           :  169.13 / shadow  129.72\n",
        "\t\"ps_calc_05\",  #           :  148.83 / shadow  120.68\n",
        "\t\"ps_ind_08_bin\",  #        :  140.73 / shadow   27.63\n",
        "\t\"ps_car_08_cat\",  #        :  120.87 / shadow   28.82\n",
        "\t\"ps_ind_09_bin\",  #        :  113.92 / shadow   27.05\n",
        "\t\"ps_ind_04_cat\",  #        :  107.27 / shadow   37.43\n",
        "\t\"ps_ind_18_bin\",  #        :   77.42 / shadow   25.97\n",
        "\t\"ps_ind_12_bin\",  #        :   39.67 / shadow   15.52\n",
        "\t\"ps_ind_14\",  #            :   37.37 / shadow   16.65\n",
        "]\n",
        "# add combinations\n",
        "combs = [\n",
        "    ('ps_reg_01', 'ps_car_02_cat'),  \n",
        "    ('ps_reg_01', 'ps_car_04_cat'),\n",
        "]"
      ],
      "metadata": {
        "id": "Lw813dADChv1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#process data\n",
        "id_test = test_df['id'].values\n",
        "id_test = train_df['id'].values\n",
        "y = train_df['target']\n",
        "\n",
        "start = time.time()\n",
        "for n_c, (f1,f2) in enumerate(combs):\n",
        "    name1 = f1 + \"_plus_\" + f2\n",
        "    print('current feature %60s %4d in %5.1f'\n",
        "          % (name1, n_c +1, (time.time() - start) / 60), end='')\n",
        "    print('\\r' * 75, end='')\n",
        "    train_df[name1] = train_df[f1].apply(lambda x:str(x)) + \"_\" + train_df[f2].apply(lambda x:str(x))\n",
        "    test_df[name1] = test_df[f1].apply(lambda x:str(x)) + \"_\" + test_df[f2].apply(lambda x: str(x))\n",
        "    #Label Encode\n",
        "    lbl = LabelEncoder()\n",
        "    lbl.fit(list(train_df[name1].values) + list(test_df[name1].values))\n",
        "    train_df[name1] = lbl.transform(list(train_df[name1].values))\n",
        "    test_df[name1] = lbl.transform(list(test_df[name1].values))\n",
        "\n",
        "    train_features.append(name1)\n",
        "\n",
        "X = train_df[train_features]\n",
        "test_df = test_df[train_features]\n",
        "\n",
        "f_cats = [f for f in X.columns if \"_cat\" in f]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QDKhY49CjOE",
        "outputId": "341bfb0e-7014-4b6b-d678-4a69747e9db8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_valid_pred = 0*y\n",
        "y_test_pred = 0"
      ],
      "metadata": {
        "id": "eQN3M3OxCjQZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set up folds\n",
        "\n",
        "K = 5\n",
        "kf = KFold(n_splits = K, random_state = 1, shuffle = True)\n",
        "np.random.seed(0)"
      ],
      "metadata": {
        "id": "pnS9EiSyCjTA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up classifier\n",
        "model = XGBClassifier(    \n",
        "                        n_estimators=MAX_ROUNDS,\n",
        "                        max_depth=4,\n",
        "                        objective=\"binary:logistic\",\n",
        "                        learning_rate=LEARNING_RATE, \n",
        "                        subsample=.8,\n",
        "                        min_child_weight=6,\n",
        "                        colsample_bytree=.8,\n",
        "                        scale_pos_weight=1.6,\n",
        "                        gamma=10,\n",
        "                        reg_alpha=8,\n",
        "                        reg_lambda=1.3,\n",
        "                     )"
      ],
      "metadata": {
        "id": "bexR6zfgCjVF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run CV\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(kf.split(train_df)):\n",
        "\n",
        "    #create data for this fold\n",
        "    y_train, y_valid = y.iloc[train_index].copy(), y.iloc[test_index]\n",
        "    X_train, X_valid = X.iloc[train_index].copy(), X.iloc[test_index, :].copy()\n",
        "    X_test = test_df.copy()\n",
        "    print('\\nFold', i)\n",
        "\n",
        "    #Encode data\n",
        "    for f in f_cats:\n",
        "        X_train[f + \"_avg\"], X_valid[f + \"_avg\"], X_test[f+ \"_avg\"] = target_encode(\n",
        "                                                        trn_series = X_train[f],\n",
        "                                                        val_series = X_valid[f],\n",
        "                                                        tst_series = X_test[f],\n",
        "                                                        target = y_train,\n",
        "                                                        min_samples_leaf = 200,\n",
        "                                                        smoothing = 10,\n",
        "                                                        noise_level = 0 \n",
        "                                                        )\n",
        "        \n",
        "\n",
        "    #Run model for this fold\n",
        "    if OPTIMIZE_ROUNDS:\n",
        "        eval_set = [(X_valid, y_valid)]\n",
        "        fit_model = model.fit( X_train, y_train,\n",
        "                               eval_set=eval_set,\n",
        "                               eval_metric=gini_xgb,\n",
        "                               early_stopping_rounds = EARLY_STOPPING_ROUNDS,\n",
        "                               verbose =False\n",
        "                              )\n",
        "        print(\"  Best N trees = \", model.best_ntree_limit)\n",
        "        print(\"  Best gini = \", model.best_score)\n",
        "\n",
        "    else:\n",
        "        fit_model = model.fit( X_train, y_train)\n",
        "\n",
        "    #Generate validation predictions\n",
        "    pred = fit_model.predict_proba(X_valid)[:,1]\n",
        "    print(\"   Gini = \", eval_gini(y_valid, pred))\n",
        "    y_valid_pred.iloc[test_index] = pred\n",
        "\n",
        "    #Accumulate test set predictions\n",
        "    y_test_pred += fit_model.predict_proba(X_test)[:,1]\n",
        "\n",
        "    del X_test, X_train, X_valid, y_train\n",
        "\n",
        "y_test_pred /= K #average test set predictions\n",
        "\n",
        "print( \"\\nGini for full training set:\")\n",
        "eval_gini(y, y_valid_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynJ5MUfhCjXs",
        "outputId": "fe7926e4-29fd-4878-ad85-1e2f7628d40b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-bb1da69def92>:1: NumbaWarning: \n",
            "Compilation is falling back to object mode WITH looplifting enabled because Function \"eval_gini\" failed type inference due to: non-precise type pyobject\n",
            "During: typing of argument at <ipython-input-5-bb1da69def92> (3)\n",
            "\n",
            "File \"<ipython-input-5-bb1da69def92>\", line 3:\n",
            "def eval_gini(y_true, y_prob):\n",
            "    y_true = np.asarray(y_true)\n",
            "    ^\n",
            "\n",
            "  @jit\n",
            "<ipython-input-5-bb1da69def92>:1: NumbaWarning: \n",
            "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"eval_gini\" failed type inference due to: cannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\n",
            "\n",
            "File \"<ipython-input-5-bb1da69def92>\", line 9:\n",
            "def eval_gini(y_true, y_prob):\n",
            "    <source elided>\n",
            "    n = len(y_true)\n",
            "    for i in range(n-1, -1, -1):\n",
            "    ^\n",
            "\n",
            "  @jit\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/object_mode_passes.py:178: NumbaWarning: Function \"eval_gini\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
            "\n",
            "File \"<ipython-input-5-bb1da69def92>\", line 3:\n",
            "def eval_gini(y_true, y_prob):\n",
            "    y_true = np.asarray(y_true)\n",
            "    ^\n",
            "\n",
            "  state.func_ir.loc))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
            "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
            "\n",
            "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
            "\n",
            "File \"<ipython-input-5-bb1da69def92>\", line 3:\n",
            "def eval_gini(y_true, y_prob):\n",
            "    y_true = np.asarray(y_true)\n",
            "    ^\n",
            "\n",
            "  state.func_ir.loc))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Gini =  0.2856959531750338\n",
            "\n",
            "Fold 1\n",
            "   Gini =  0.2825270426290394\n",
            "\n",
            "Fold 2\n",
            "   Gini =  0.2744124272744569\n",
            "\n",
            "Fold 3\n",
            "   Gini =  0.29925913576337726\n",
            "\n",
            "Fold 4\n",
            "   Gini =  0.28468083823013424\n",
            "\n",
            "Gini for full training set:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-bb1da69def92>:1: NumbaWarning: \n",
            "Compilation is falling back to object mode WITH looplifting enabled because Function \"eval_gini\" failed type inference due to: non-precise type pyobject\n",
            "During: typing of argument at <ipython-input-5-bb1da69def92> (3)\n",
            "\n",
            "File \"<ipython-input-5-bb1da69def92>\", line 3:\n",
            "def eval_gini(y_true, y_prob):\n",
            "    y_true = np.asarray(y_true)\n",
            "    ^\n",
            "\n",
            "  @jit\n",
            "<ipython-input-5-bb1da69def92>:1: NumbaWarning: \n",
            "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"eval_gini\" failed type inference due to: cannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\n",
            "\n",
            "File \"<ipython-input-5-bb1da69def92>\", line 9:\n",
            "def eval_gini(y_true, y_prob):\n",
            "    <source elided>\n",
            "    n = len(y_true)\n",
            "    for i in range(n-1, -1, -1):\n",
            "    ^\n",
            "\n",
            "  @jit\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/object_mode_passes.py:178: NumbaWarning: Function \"eval_gini\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
            "\n",
            "File \"<ipython-input-5-bb1da69def92>\", line 3:\n",
            "def eval_gini(y_true, y_prob):\n",
            "    y_true = np.asarray(y_true)\n",
            "    ^\n",
            "\n",
            "  state.func_ir.loc))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
            "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
            "\n",
            "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
            "\n",
            "File \"<ipython-input-5-bb1da69def92>\", line 3:\n",
            "def eval_gini(y_true, y_prob):\n",
            "    y_true = np.asarray(y_true)\n",
            "    ^\n",
            "\n",
            "  state.func_ir.loc))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.28509183378958614"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rwpOdJNZJKqg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}