{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modeling",
      "provenance": [],
      "authorship_tag": "ABX9TyM2LeYIOO9cnFhN3hEw7XC5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Simple modeling\n",
        "\n",
        "#### Cross validate models\n",
        "\n",
        "가장 유명한 classifiers를 비교하여 정확성을 평가하고 cross validation procedure를 거칠 것입니다.\n",
        "\n",
        "SVC\n",
        "\n",
        "Decision Tree\n",
        "\n",
        "AdaBoost\n",
        "\n",
        "Random Forest\n",
        "\n",
        "Extra Trees\n",
        "\n",
        "Gradient Boosting\n",
        "\n",
        "Multiple layer perceprton (neural network)\n",
        "\n",
        "KNN\n",
        "\n",
        "Logistic regression\n",
        "\n",
        "Linear Discriminant Analysis\n",
        "\n",
        "<br>\n",
        "\n",
        "#### 10 types Cross validation scores\n",
        "\n",
        "```\n",
        "#Cross validate model with Kfold stratified cross val\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=10)\n",
        "\n",
        "#Modeling step Test differencts algorithms\n",
        "# Modeling step Test differents algorithms \n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import  DecisionTreeClassifier\n",
        "\n",
        "\n",
        "random_state = 2\n",
        "classifiers = []\n",
        "classifiers.append(SVC(random_state=random_state))\n",
        "classifiers.append(DecisionTreeClassifier(random_state=random_state))\n",
        "classifiers.append(AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state),random_state=random_state,learning_rate=0.1))\n",
        "classifiers.append(RandomForestClassifier(random_state=random_state))\n",
        "classifiers.append(ExtraTreesClassifier(random_state=random_state))\n",
        "classifiers.append(GradientBoostingClassifier(random_state=random_state))\n",
        "classifiers.append(MLPClassifier(random_state=random_state))\n",
        "classifiers.append(KNeighborsClassifier())\n",
        "classifiers.append(LogisticRegression(random_state = random_state))\n",
        "classifiers.append(LinearDiscriminantAnalysis())\n",
        "\n",
        "cv_results = []\n",
        "for classifier in classifiers :\n",
        "    cv_results.append(cross_val_score(classifier, X_train, y = Y_train, scoring = \"accuracy\", cv = kfold, n_jobs=4))\n",
        "\n",
        "cv_means = []\n",
        "cv_std = []\n",
        "for cv_result in cv_results:\n",
        "    cv_means.append(cv_result.mean())\n",
        "    cv_std.append(cv_result.std())\n",
        "\n",
        "cv_res = pd.DataFrame({\"CrossValMeans\":cv_means,\"CrossValerrors\": cv_std,\"Algorithm\":[\"SVC\",\"DecisionTree\",\"AdaBoost\",\n",
        "\"RandomForest\",\"ExtraTrees\",\"GradientBoosting\",\"MultipleLayerPerceptron\",\"KNeighboors\",\"LogisticRegression\",\"LinearDiscriminantAnalysis\"]})\n",
        "\n",
        "g = sns.barplot(\"CrossValMeans\",\"Algorithm\",data = cv_res, palette=\"Set3\",orient = \"h\",**{'xerr':cv_std})\n",
        "g.set_xlabel(\"Mean Accuracy\")\n",
        "g = g.set_title(\"Cross validation scores\")\n",
        "\n",
        "```\n",
        "![](https://media.vlpt.us/images/qsdcfd/post/68166046-e42e-496a-986f-d640fb405a7b/image.png)\n",
        "\n",
        "<br>\n",
        "\n",
        "#### Hyperparameter tunning for best models\n",
        "\n",
        "**그리디 기법 최적화**\n",
        "\n",
        "##### AdaBoost\n",
        "\n",
        "```\n",
        "### META MODELING WITH ADABOOST, RF, EXTRATREES and GRADIENTBOOSTING\n",
        "\n",
        "#Adaboost\n",
        "\n",
        "DTC = DecisionTreeClassifier()\n",
        "\n",
        "adaDTC = AdaBoostClassifier(DTC, random_state=7)\n",
        "\n",
        "ada_param_grid = {\"base_estimator__criterion\" : [\"gin1\",\"entropy\"],\"base_estimator__splitter\" : [\"best\", \"random\"], \"algorithm\" : [\"SAMME\",\"SAMME.R\"], \"n_estimators\" :[1,2], \"learning_rate\": [0.0001,0.001,0.01,0.1,0.2,0.3,1.5]}\n",
        "\n",
        "gsadaDTC = GridSearchCV(adaDTC, param_grid = ada_param_grid, cv = kfold, scoring=\"accuracy\", n_jobs = 4, verbose=1)\n",
        "\n",
        "gsadaDTC.fit(X_train,Y_train)\n",
        "\n",
        "ada_best = gsadaDTC.best_estimator_\n",
        "```\n",
        "![](https://media.vlpt.us/images/qsdcfd/post/bc8f1230-a198-4fba-bde8-b532f2e77894/image.png)\n",
        "\n",
        "```\n",
        "gsadaDTC.best_score_  #0.8275536261491316\n",
        "```\n",
        "<br>\n",
        "\n",
        "##### ExtraTrees\n",
        "\n",
        "```\n",
        "#ExtraTrees\n",
        "ExtC = ExtraTreesClassifier()\n",
        "\n",
        "##Searchh grid for optimal parameters\n",
        "\n",
        "ex_param_grid = {\"max_depth\": [None], \"max_features\":[1,3,10],\"min_samples_split\":[2,3,10],\"min_samples_leaf\":[1,3,10],\"bootstrap\":[False],\"n_estimators\":[100,300], \"criterion\":[\"gini\"]}\n",
        "\n",
        "gsExtC = GridSearchCV(ExtC, param_grid = ex_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs=4, verbose=1)\n",
        "\n",
        "gsExtC.fit(X_train, Y_train)\n",
        "\n",
        "ExtC_best = gsExtC.best_estimator_\n",
        "\n",
        "#Best score\n",
        "\n",
        "gsExtC.best_score_\n",
        "```\n",
        "![](https://media.vlpt.us/images/qsdcfd/post/cc4f8f39-767a-4487-9efa-e2bb1fc29413/image.png)\n",
        "\n",
        "<br>\n",
        "\n",
        "##### RandomForest\n",
        "\n",
        "```\n",
        "# RFC Parameters tunning \n",
        "RFC = RandomForestClassifier()\n",
        "\n",
        "\n",
        "## Search grid for optimal parameters\n",
        "rf_param_grid = {\"max_depth\": [None],\n",
        "              \"max_features\": [1, 3, 10],\n",
        "              \"min_samples_split\": [2, 3, 10],\n",
        "              \"min_samples_leaf\": [1, 3, 10],\n",
        "              \"bootstrap\": [False],\n",
        "              \"n_estimators\" :[100,300],\n",
        "              \"criterion\": [\"gini\"]}\n",
        "\n",
        "\n",
        "gsRFC = GridSearchCV(RFC,param_grid = rf_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n",
        "\n",
        "gsRFC.fit(X_train,Y_train)\n",
        "\n",
        "RFC_best = gsRFC.best_estimator_\n",
        "\n",
        "# Best score\n",
        "gsRFC.best_score_\n",
        "```\n",
        "\n",
        "![](https://media.vlpt.us/images/qsdcfd/post/aab71b7f-af8e-4cb0-836f-ae1011c2516a/image.png)\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "##### GradientBoosting and SVC classifiers\n",
        "\n",
        "```\n",
        "#GradientBoostingClassifier()\n",
        "\n",
        "GBC = GradientBoostingClassifier()\n",
        "gb_param_grid = {'loss': [\"deviance\"], \"n_estimators\": [100,200,300], \"learning_rate\":[0.1,0.05,0.01],\"max_depth\": [4,8], \"min_samples_leaf\":[100,150],\"max_features\":[0.3,0.1]}\n",
        "\n",
        "gsGBC = GridSearchCV(GBC, param_grid = gb_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs=4, verbose=1)\n",
        "\n",
        "gsGBC.fit(X_train, Y_train)\n",
        "\n",
        "GBC_best = gsGBC.best_estimator_\n",
        "\n",
        "#Best score\n",
        "\n",
        "gsGBC.best_score_\n",
        "```\n",
        "\n",
        "![](https://media.vlpt.us/images/qsdcfd/post/398d2ef5-0443-4f25-a56b-ff54300cace4/image.png)\n",
        "\n",
        "```\n",
        "#SVC Classifier\n",
        "\n",
        "SVMC = SVC(probability = True)\n",
        "svc_param_grid = {'kernel' : ['rbf'], 'gamma': [0.001,0.01,0.1,1], 'C': [1,10,50,100,200,300,1000]}\n",
        "\n",
        "gsSVMC = GridSearchCV(SVMC, param_grid = svc_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs = 4, verbose=1)\n",
        "\n",
        "gsSVMC.fit(X_train, Y_train)\n",
        "\n",
        "SVMC_best = gsSVMC.best_estimator_\n",
        "\n",
        "#Best score\n",
        "\n",
        "gsSVMC.best_score_\n",
        "```\n",
        "![](https://media.vlpt.us/images/qsdcfd/post/3a574517-bf76-436b-ad44-3417ec54a6a6/image.png)\n",
        "\n",
        "<br>\n",
        "\n",
        "### Plot learning curves\n",
        "\n",
        "```\n",
        "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
        "                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "    \"\"\"Generate a simple plot of the test and training learning curve\"\"\"\n",
        "    plt.figure()\n",
        "    plt.title(title)\n",
        "    if ylim is not None:\n",
        "        plt.ylim(*ylim)\n",
        "    plt.xlabel(\"Training examples\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    train_sizes, train_scores, test_scores = learning_curve(\n",
        "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    plt.grid()\n",
        "\n",
        "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                     color=\"r\")\n",
        "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
        "             label=\"Training score\")\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
        "             label=\"Cross-validation score\")\n",
        "\n",
        "    plt.legend(loc=\"best\")\n",
        "    return plt\n",
        "\n",
        "g = plot_learning_curve(gsRFC.best_estimator_,\"RF mearning curves\",X_train,Y_train,cv=kfold)\n",
        "g = plot_learning_curve(gsExtC.best_estimator_,\"ExtraTrees learning curves\",X_train,Y_train,cv=kfold)\n",
        "g = plot_learning_curve(gsSVMC.best_estimator_,\"SVC learning curves\",X_train,Y_train,cv=kfold)\n",
        "g = plot_learning_curve(gsadaDTC.best_estimator_,\"AdaBoost learning curves\",X_train,Y_train,cv=kfold)\n",
        "g = plot_learning_curve(gsGBC.best_estimator_,\"GradientBoosting learning curves\",X_train,Y_train,cv=kfold)\n",
        "```\n",
        "\n",
        "![](https://media.vlpt.us/images/qsdcfd/post/dffb57b0-c5dd-4a25-9b68-2e696592df3f/image.png)\n",
        "\n",
        "![](https://media.vlpt.us/images/qsdcfd/post/27f2b7bd-e827-4707-b560-603591a93e71/image.png)\n",
        "\n",
        "![](https://media.vlpt.us/images/qsdcfd/post/ae9da293-f09a-45df-a5e6-4f079e592f08/image.png)\n",
        "\n",
        "<br>\n",
        "\n",
        "### Feature importance of tree based classifiers\n",
        "\n",
        "```\n",
        "nrows = ncols = 2\n",
        "fig, axes = plt.subplots(nrows = nrows, ncols = ncols, sharex=\"all\", figsize=(15,15))\n",
        "\n",
        "names_classifiers = [(\"AdaBoosting\", ada_best),(\"ExtraTrees\",ExtC_best),(\"RandomForest\",RFC_best),(\"GradientBoosting\",GBC_best)]\n",
        "\n",
        "nclassifier = 0\n",
        "for row in range(nrows):\n",
        "    for col in range(ncols):\n",
        "        name = names_classifiers[nclassifier][0]\n",
        "        classifier = names_classifiers[nclassifier][1]\n",
        "        indices = np.argsort(classifier.feature_importances_)[::-1][:40]\n",
        "        g = sns.barplot(y=X_train.columns[indices][:40],x = classifier.feature_importances_[indices][:40] , orient='h',ax=axes[row][col])\n",
        "        g.set_xlabel(\"Relative importance\",fontsize=12)\n",
        "        g.set_ylabel(\"Features\",fontsize=12)\n",
        "        g.tick_params(labelsize=9)\n",
        "        g.set_title(name + \" feature importance\")\n",
        "        nclassifier += 1\n",
        "```\n",
        "![](https://media.vlpt.us/images/qsdcfd/post/eff1917b-a73f-482c-8e01-e9eb337df855/image.png)\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "According to the feature importance of this 4 classifiers, the prediction of the survival seems to be more associated with the Age, the Sex, the family size and the social standing of the passengers more than the location in the boat.\n",
        "\n",
        "\n",
        "```\n",
        "test_Survived_RFC = pd.Series(RFC_best.predict(test), name=\"RFC\")\n",
        "test_Survived_ExtC = pd.Series(ExtC_best.predict(test), name=\"ExtC\")\n",
        "test_Survived_SVMC = pd.Series(SVMC_best.predict(test), name=\"SVC\")\n",
        "test_Survived_AdaC = pd.Series(ada_best.predict(test), name=\"Ada\")\n",
        "test_Survived_GBC = pd.Series(GBC_best.predict(test), name=\"GBC\")\n",
        "\n",
        "\n",
        "# Concatenate all classifier results\n",
        "ensemble_results = pd.concat([test_Survived_RFC,test_Survived_ExtC,test_Survived_AdaC,test_Survived_GBC, test_Survived_SVMC],axis=1)\n",
        "\n",
        "\n",
        "g= sns.heatmap(ensemble_results.corr(),annot=True)\n",
        "```\n",
        "![](https://media.vlpt.us/images/qsdcfd/post/a44a4533-9bca-41f4-ae8b-e5a185e23e1c/image.png)\n",
        "\n",
        "<br>\n",
        "\n",
        "### Ensemble modeling\n",
        "\n",
        "\n",
        "```\n",
        "votingC = VotingClassifier(estimators=[('rfc', RFC_best), ('extc', ExtC_best),\n",
        "('svc', SVMC_best), ('adac',ada_best),('gbc',GBC_best)], voting='soft', n_jobs=4)\n",
        "\n",
        "votingC = votingC.fit(X_train, Y_train)\n",
        "```\n",
        "\n",
        "<br>\n",
        "\n",
        "### Prediction\n",
        "\n",
        "```\n",
        "test_Survived = pd.Series(votingC.predict(test), name=\"Survived\")\n",
        "results = pd.concat([IDtest, test_Survived], axis=1)\n",
        "results.to_csv(\"ensemble_python_voting.csv\", index=False)\n",
        "```"
      ],
      "metadata": {
        "id": "TWfQtZVqZb12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PQEBERy9ZfXn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}